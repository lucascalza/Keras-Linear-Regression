{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Conv1D, MaxPooling1D, MaxPooling2D, AveragePooling2D, Conv2D, Flatten, Dropout, Input, concatenate, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "\n",
    "\n",
    "#The following is needed in order to display every column of a given row inside a database\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this notebook is to play around with a dataset obtained from Kaggle at the following link:\n",
    "https://www.kaggle.com/datasets/dgawlik/nyse\n",
    "\n",
    "Inside of the link there will be four .csv files:\n",
    "- prices;\n",
    "- fundamentals;\n",
    "- securities;\n",
    "- prices adjusted;\n",
    "\n",
    "The description for each of these is found at the link above. The notebook is devoted to try and apply a very simple 1-feature linear regression between two columns of the dataset \"fundamentals\", here named \"dataset_fundamentals\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I've done is to load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prices = pd.read_csv(r'NewYorkStockExchange/prices.csv')\n",
    "dataset_fundamentals = pd.read_csv(r'NewYorkStockExchange/fundamentals.csv')\n",
    "dataset_securities = pd.read_csv(r'NewYorkStockExchange/securities.csv')\n",
    "dataset_adjusted = pd.read_csv(r'NewYorkStockExchange/prices-split-adjusted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any columns inside the database that contain string-like values; if this happens then store those inside the \"col_to_numeric\" list for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker Symbol\n",
      "Period Ending\n"
     ]
    }
   ],
   "source": [
    "col_to_numeric = []\n",
    "\n",
    "for column in dataset_fundamentals:\n",
    "    if type(dataset_fundamentals[column][0]) == type('stringa'):\n",
    "        col_to_numeric = np.append(col_to_numeric, column)\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above list, it is possible to employ the \"to_numeric()\" method to parse these string values into numeric values; the \"errors = coerce\" argument makes sure that if the parsing cannot be done, the value employed is a NaN, to be treated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_to_numeric:\n",
    "    dataset_fundamentals[col] = pd.to_numeric(dataset_fundamentals[col], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing which columns contain string values, after parsing the values into numericals which result in most of them being NaN, these are filled with 0's. This doesn't represent a problem in the dataset, since the training via a ML model will be done on other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_to_numeric:\n",
    "    dataset_fundamentals[col] = dataset_fundamentals[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether there are any NaN values left over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                        0\n",
       "Ticker Symbol                     0\n",
       "Period Ending                     0\n",
       "Accounts Payable                  0\n",
       "Accounts Receivable               0\n",
       "                               ... \n",
       "Total Revenue                     0\n",
       "Treasury Stock                    0\n",
       "For Year                        173\n",
       "Earnings Per Share              219\n",
       "Estimated Shares Outstanding    219\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fundamentals.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the implementation of seaborn via the construction of a correlation matrix, which gives an idea of how much correlated the different columns inside the dataset are. The values range from 0 to 1 for correlation, 0 meaning no correlation at all and 1 meaning very strong correlation. To help the search of closely correlated columns, from the correlation matrix I only kept the correlation values higher than or equal to 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "corr_matrix = dataset_fundamentals.corr()\n",
    "above_corr = corr_matrix[corr_matrix >= 0.8]\n",
    "plt.figure(figsize = (20, 9))\n",
    "sns.heatmap(above_corr, cmap = 'Blues', center = 0, annot = False, square = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I picked two columns that were strongly correlated and decided to saw how this correlation looked like. Since the idea was to go for a ML model for a linear regression, I was looking for two columns that were linearly correlated with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x18e578c05e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pairplot(dataset_fundamentals[['Net Cash Flow-Operating', 'Earnings Before Interest and Tax']], diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a part of preprocessing, both for the features as well as for the labels. Noting that the values to train the model on weren't many, I've decided to generate more. But in order to do so I needed to find the distribution according to which the values were distributed, to then sample from there.\n",
    "\n",
    "The following cell details how I did this, while the one after this one takes all of these same steps but applies them to the labels.\n",
    "First of all I took note of the distribution of values in the column of interest for the features, here 'Net Cash Flow-Operating'; then I normalized the heights of the bins under \"len_trial\"; after that I took out the last value of the edges of the bins, in \"arr_hist_trial\"; these steps are needed for the np.random.choice function, which generates samples that are stored in \"features_distrib\".\n",
    "The plot resulting from this cell shows how distributed the original values (in blue) and the generated values (in orange) are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   3.,   4.,  10.,  17.,  67.,\n",
       "        376., 309., 151.,  64.,  92.,  75.,  50.,  34.,  36.,  19.,  21.,\n",
       "         13.,  21.,  11.,  10.,   9.,   6.,   6.,   8.,   7.,   8.,   0.,\n",
       "          1.,   0.,   7.,   5.,   2.,   2.,   0.,   4.,   0.,   1.,   3.,\n",
       "          2.,   1.,   0.,   0.,   0.,   3.,   0.,   1.,   0.,   0.,   1.,\n",
       "          0.,   0.,   2.,   0.,   0.,   2.,   1.,   0.,   0.,   0.,   2.,\n",
       "          0.,   2.,   2.,   0.,   1.,   1.,   3.,   1.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   3.,   0.,   1.,   0.,   3.,   0.,   0.,   0.,\n",
       "          1.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   1.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.]),\n",
       " array([-1.60560000e+10, -1.55619481e+10, -1.50678963e+10, -1.45738444e+10,\n",
       "        -1.40797926e+10, -1.35857407e+10, -1.30916889e+10, -1.25976370e+10,\n",
       "        -1.21035852e+10, -1.16095333e+10, -1.11154814e+10, -1.06214296e+10,\n",
       "        -1.01273777e+10, -9.63332587e+09, -9.13927402e+09, -8.64522216e+09,\n",
       "        -8.15117030e+09, -7.65711845e+09, -7.16306659e+09, -6.66901474e+09,\n",
       "        -6.17496288e+09, -5.68091102e+09, -5.18685917e+09, -4.69280731e+09,\n",
       "        -4.19875546e+09, -3.70470360e+09, -3.21065174e+09, -2.71659989e+09,\n",
       "        -2.22254803e+09, -1.72849618e+09, -1.23444432e+09, -7.40392464e+08,\n",
       "        -2.46340608e+08,  2.47711248e+08,  7.41763104e+08,  1.23581496e+09,\n",
       "         1.72986682e+09,  2.22391867e+09,  2.71797053e+09,  3.21202238e+09,\n",
       "         3.70607424e+09,  4.20012610e+09,  4.69417795e+09,  5.18822981e+09,\n",
       "         5.68228166e+09,  6.17633352e+09,  6.67038538e+09,  7.16443723e+09,\n",
       "         7.65848909e+09,  8.15254094e+09,  8.64659280e+09,  9.14064466e+09,\n",
       "         9.63469651e+09,  1.01287484e+10,  1.06228002e+10,  1.11168521e+10,\n",
       "         1.16109039e+10,  1.21049558e+10,  1.25990076e+10,  1.30930595e+10,\n",
       "         1.35871114e+10,  1.40811632e+10,  1.45752151e+10,  1.50692669e+10,\n",
       "         1.55633188e+10,  1.60573706e+10,  1.65514225e+10,  1.70454744e+10,\n",
       "         1.75395262e+10,  1.80335781e+10,  1.85276299e+10,  1.90216818e+10,\n",
       "         1.95157336e+10,  2.00097855e+10,  2.05038373e+10,  2.09978892e+10,\n",
       "         2.14919411e+10,  2.19859929e+10,  2.24800448e+10,  2.29740966e+10,\n",
       "         2.34681485e+10,  2.39622003e+10,  2.44562522e+10,  2.49503040e+10,\n",
       "         2.54443559e+10,  2.59384078e+10,  2.64324596e+10,  2.69265115e+10,\n",
       "         2.74205633e+10,  2.79146152e+10,  2.84086670e+10,  2.89027189e+10,\n",
       "         2.93967708e+10,  2.98908226e+10,  3.03848745e+10,  3.08789263e+10,\n",
       "         3.13729782e+10,  3.18670300e+10,  3.23610819e+10,  3.28551337e+10,\n",
       "         3.33491856e+10,  3.38432375e+10,  3.43372893e+10,  3.48313412e+10,\n",
       "         3.53253930e+10,  3.58194449e+10,  3.63134967e+10,  3.68075486e+10,\n",
       "         3.73016004e+10,  3.77956523e+10,  3.82897042e+10,  3.87837560e+10,\n",
       "         3.92778079e+10,  3.97718597e+10,  4.02659116e+10,  4.07599634e+10,\n",
       "         4.12540153e+10,  4.17480672e+10,  4.22421190e+10,  4.27361709e+10,\n",
       "         4.32302227e+10,  4.37242746e+10,  4.42183264e+10,  4.47123783e+10,\n",
       "         4.52064301e+10,  4.57004820e+10,  4.61945339e+10,  4.66885857e+10,\n",
       "         4.71826376e+10,  4.76766894e+10,  4.81707413e+10,  4.86647931e+10,\n",
       "         4.91588450e+10,  4.96528968e+10,  5.01469487e+10,  5.06410006e+10,\n",
       "         5.11350524e+10,  5.16291043e+10,  5.21231561e+10,  5.26172080e+10,\n",
       "         5.31112598e+10,  5.36053117e+10,  5.40993636e+10,  5.45934154e+10,\n",
       "         5.50874673e+10,  5.55815191e+10,  5.60755710e+10,  5.65696228e+10,\n",
       "         5.70636747e+10,  5.75577265e+10,  5.80517784e+10,  5.85458303e+10,\n",
       "         5.90398821e+10,  5.95339340e+10,  6.00279858e+10,  6.05220377e+10,\n",
       "         6.10160895e+10,  6.15101414e+10,  6.20041932e+10,  6.24982451e+10,\n",
       "         6.29922970e+10,  6.34863488e+10,  6.39804007e+10,  6.44744525e+10,\n",
       "         6.49685044e+10,  6.54625562e+10,  6.59566081e+10,  6.64506600e+10,\n",
       "         6.69447118e+10,  6.74387637e+10,  6.79328155e+10,  6.84268674e+10,\n",
       "         6.89209192e+10,  6.94149711e+10,  6.99090229e+10,  7.04030748e+10,\n",
       "         7.08971267e+10,  7.13911785e+10,  7.18852304e+10,  7.23792822e+10,\n",
       "         7.28733341e+10,  7.33673859e+10,  7.38614378e+10,  7.43554896e+10,\n",
       "         7.48495415e+10,  7.53435934e+10,  7.58376452e+10,  7.63316971e+10,\n",
       "         7.68257489e+10,  7.73198008e+10,  7.78138526e+10,  7.83079045e+10,\n",
       "         7.88019564e+10,  7.92960082e+10,  7.97900601e+10,  8.02841119e+10,\n",
       "         8.07781638e+10,  8.12722156e+10,  8.17662675e+10,  8.22603193e+10,\n",
       "         8.27543712e+10,  8.32484231e+10,  8.37424749e+10,  8.42365268e+10,\n",
       "         8.47305786e+10,  8.52246305e+10,  8.57186823e+10,  8.62127342e+10,\n",
       "         8.67067860e+10,  8.72008379e+10,  8.76948898e+10,  8.81889416e+10,\n",
       "         8.86829935e+10,  8.91770453e+10,  8.96710972e+10,  9.01651490e+10,\n",
       "         9.06592009e+10,  9.11532528e+10,  9.16473046e+10,  9.21413565e+10,\n",
       "         9.26354083e+10,  9.31294602e+10,  9.36235120e+10,  9.41175639e+10,\n",
       "         9.46116157e+10,  9.51056676e+10,  9.55997195e+10,  9.60937713e+10,\n",
       "         9.65878232e+10,  9.70818750e+10,  9.75759269e+10,  9.80699787e+10,\n",
       "         9.85640306e+10,  9.90580824e+10,  9.95521343e+10,  1.00046186e+11,\n",
       "         1.00540238e+11,  1.01034290e+11,  1.01528342e+11,  1.02022394e+11,\n",
       "         1.02516445e+11,  1.03010497e+11,  1.03504549e+11,  1.03998601e+11,\n",
       "         1.04492653e+11,  1.04986705e+11,  1.05480757e+11,  1.05974808e+11,\n",
       "         1.06468860e+11,  1.06962912e+11,  1.07456964e+11]),\n",
       " <BarContainer object of 250 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 250\n",
    "size = 1500\n",
    "\n",
    "arr_hist = plt.hist(dataset_fundamentals['Net Cash Flow-Operating'], bins = k)\n",
    "len_trial = arr_hist[0] / np.sum(arr_hist[0])\n",
    "arr_hist_trial = arr_hist[1][:-1]\n",
    "\n",
    "features_distrib = np.random.choice(a = arr_hist_trial, p = len_trial, size = size)\n",
    "\n",
    "plt.hist(features_distrib, bins = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is done here, but for the labels which are taken as the column of the dataset, named 'Earnings Before Interest and Tax'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   1.,   1.,   0.,   0.,   0.,   4.,   0.,   3.,   2.,\n",
       "          0.,   4.,   0.,   2.,   4.,   3.,   7.,  11., 122., 335., 280.,\n",
       "        171.,  77.,  68.,   0.,  46.,  38.,  46.,  35.,  26.,  20.,   9.,\n",
       "         18.,  14.,  14.,   7.,   4.,  11.,  10.,   0.,   2.,   5.,   8.,\n",
       "          3.,   4.,   0.,   4.,   3.,   6.,   1.,   3.,   1.,   5.,   1.,\n",
       "          0.,   0.,   4.,   3.,   0.,   0.,   0.,   4.,   1.,   0.,   1.,\n",
       "          0.,   0.,   0.,   0.,   0.,   4.,   0.,   0.,   0.,   2.,   0.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,\n",
       "          1.,   2.,   5.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   1.,\n",
       "          0.,   2.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   2.,\n",
       "          1.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   2.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   1.,   0.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.]),\n",
       " array([-2.10802800e+10, -2.06814586e+10, -2.02826371e+10, -1.98838157e+10,\n",
       "        -1.94849942e+10, -1.90861728e+10, -1.86873514e+10, -1.82885299e+10,\n",
       "        -1.78897085e+10, -1.74908870e+10, -1.70920656e+10, -1.66932442e+10,\n",
       "        -1.62944227e+10, -1.58956013e+10, -1.54967798e+10, -1.50979584e+10,\n",
       "        -1.46991370e+10, -1.43003155e+10, -1.39014941e+10, -1.35026726e+10,\n",
       "        -1.31038512e+10, -1.27050298e+10, -1.23062083e+10, -1.19073869e+10,\n",
       "        -1.15085654e+10, -1.11097440e+10, -1.07109226e+10, -1.03121011e+10,\n",
       "        -9.91327968e+09, -9.51445824e+09, -9.11563680e+09, -8.71681536e+09,\n",
       "        -8.31799392e+09, -7.91917248e+09, -7.52035104e+09, -7.12152960e+09,\n",
       "        -6.72270816e+09, -6.32388672e+09, -5.92506528e+09, -5.52624384e+09,\n",
       "        -5.12742240e+09, -4.72860096e+09, -4.32977952e+09, -3.93095808e+09,\n",
       "        -3.53213664e+09, -3.13331520e+09, -2.73449376e+09, -2.33567232e+09,\n",
       "        -1.93685088e+09, -1.53802944e+09, -1.13920800e+09, -7.40386560e+08,\n",
       "        -3.41565120e+08,  5.72563200e+07,  4.56077760e+08,  8.54899200e+08,\n",
       "         1.25372064e+09,  1.65254208e+09,  2.05136352e+09,  2.45018496e+09,\n",
       "         2.84900640e+09,  3.24782784e+09,  3.64664928e+09,  4.04547072e+09,\n",
       "         4.44429216e+09,  4.84311360e+09,  5.24193504e+09,  5.64075648e+09,\n",
       "         6.03957792e+09,  6.43839936e+09,  6.83722080e+09,  7.23604224e+09,\n",
       "         7.63486368e+09,  8.03368512e+09,  8.43250656e+09,  8.83132800e+09,\n",
       "         9.23014944e+09,  9.62897088e+09,  1.00277923e+10,  1.04266138e+10,\n",
       "         1.08254352e+10,  1.12242566e+10,  1.16230781e+10,  1.20218995e+10,\n",
       "         1.24207210e+10,  1.28195424e+10,  1.32183638e+10,  1.36171853e+10,\n",
       "         1.40160067e+10,  1.44148282e+10,  1.48136496e+10,  1.52124710e+10,\n",
       "         1.56112925e+10,  1.60101139e+10,  1.64089354e+10,  1.68077568e+10,\n",
       "         1.72065782e+10,  1.76053997e+10,  1.80042211e+10,  1.84030426e+10,\n",
       "         1.88018640e+10,  1.92006854e+10,  1.95995069e+10,  1.99983283e+10,\n",
       "         2.03971498e+10,  2.07959712e+10,  2.11947926e+10,  2.15936141e+10,\n",
       "         2.19924355e+10,  2.23912570e+10,  2.27900784e+10,  2.31888998e+10,\n",
       "         2.35877213e+10,  2.39865427e+10,  2.43853642e+10,  2.47841856e+10,\n",
       "         2.51830070e+10,  2.55818285e+10,  2.59806499e+10,  2.63794714e+10,\n",
       "         2.67782928e+10,  2.71771142e+10,  2.75759357e+10,  2.79747571e+10,\n",
       "         2.83735786e+10,  2.87724000e+10,  2.91712214e+10,  2.95700429e+10,\n",
       "         2.99688643e+10,  3.03676858e+10,  3.07665072e+10,  3.11653286e+10,\n",
       "         3.15641501e+10,  3.19629715e+10,  3.23617930e+10,  3.27606144e+10,\n",
       "         3.31594358e+10,  3.35582573e+10,  3.39570787e+10,  3.43559002e+10,\n",
       "         3.47547216e+10,  3.51535430e+10,  3.55523645e+10,  3.59511859e+10,\n",
       "         3.63500074e+10,  3.67488288e+10,  3.71476502e+10,  3.75464717e+10,\n",
       "         3.79452931e+10,  3.83441146e+10,  3.87429360e+10,  3.91417574e+10,\n",
       "         3.95405789e+10,  3.99394003e+10,  4.03382218e+10,  4.07370432e+10,\n",
       "         4.11358646e+10,  4.15346861e+10,  4.19335075e+10,  4.23323290e+10,\n",
       "         4.27311504e+10,  4.31299718e+10,  4.35287933e+10,  4.39276147e+10,\n",
       "         4.43264362e+10,  4.47252576e+10,  4.51240790e+10,  4.55229005e+10,\n",
       "         4.59217219e+10,  4.63205434e+10,  4.67193648e+10,  4.71181862e+10,\n",
       "         4.75170077e+10,  4.79158291e+10,  4.83146506e+10,  4.87134720e+10,\n",
       "         4.91122934e+10,  4.95111149e+10,  4.99099363e+10,  5.03087578e+10,\n",
       "         5.07075792e+10,  5.11064006e+10,  5.15052221e+10,  5.19040435e+10,\n",
       "         5.23028650e+10,  5.27016864e+10,  5.31005078e+10,  5.34993293e+10,\n",
       "         5.38981507e+10,  5.42969722e+10,  5.46957936e+10,  5.50946150e+10,\n",
       "         5.54934365e+10,  5.58922579e+10,  5.62910794e+10,  5.66899008e+10,\n",
       "         5.70887222e+10,  5.74875437e+10,  5.78863651e+10,  5.82851866e+10,\n",
       "         5.86840080e+10,  5.90828294e+10,  5.94816509e+10,  5.98804723e+10,\n",
       "         6.02792938e+10,  6.06781152e+10,  6.10769366e+10,  6.14757581e+10,\n",
       "         6.18745795e+10,  6.22734010e+10,  6.26722224e+10,  6.30710438e+10,\n",
       "         6.34698653e+10,  6.38686867e+10,  6.42675082e+10,  6.46663296e+10,\n",
       "         6.50651510e+10,  6.54639725e+10,  6.58627939e+10,  6.62616154e+10,\n",
       "         6.66604368e+10,  6.70592582e+10,  6.74580797e+10,  6.78569011e+10,\n",
       "         6.82557226e+10,  6.86545440e+10,  6.90533654e+10,  6.94521869e+10,\n",
       "         6.98510083e+10,  7.02498298e+10,  7.06486512e+10,  7.10474726e+10,\n",
       "         7.14462941e+10,  7.18451155e+10,  7.22439370e+10,  7.26427584e+10,\n",
       "         7.30415798e+10,  7.34404013e+10,  7.38392227e+10,  7.42380442e+10,\n",
       "         7.46368656e+10,  7.50356870e+10,  7.54345085e+10,  7.58333299e+10,\n",
       "         7.62321514e+10,  7.66309728e+10,  7.70297942e+10,  7.74286157e+10,\n",
       "         7.78274371e+10,  7.82262586e+10,  7.86250800e+10]),\n",
       " <BarContainer object of 250 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_hist = plt.hist(dataset_fundamentals['Earnings Before Interest and Tax'], bins = k)\n",
    "len_trial = arr_hist[0] / np.sum(arr_hist[0])\n",
    "arr_hist_trial = arr_hist[1][:-1]\n",
    "\n",
    "labels_distrib = np.random.choice(a = arr_hist_trial, p = len_trial, size = size)\n",
    "\n",
    "plt.hist(labels_distrib, bins = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot shows how the generated and the original values fare one against the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18e63462a60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(features_distrib, labels_distrib)\n",
    "plt.scatter(dataset_fundamentals['Net Cash Flow-Operating'], dataset_fundamentals['Earnings Before Interest and Tax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the generated data to the original one, both for the features and for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_noisy = np.concatenate((dataset_fundamentals['Net Cash Flow-Operating'], features_distrib), axis = 0)\n",
    "labels_noisy = np.concatenate((dataset_fundamentals['Earnings Before Interest and Tax'], labels_distrib), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another scatter plot that shows how the final data looks like with respect to the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18e676afdc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(dataset_fundamentals['Earnings Before Interest and Tax'], dataset_fundamentals['Net Cash Flow-Operating'])\n",
    "plt.scatter(features_noisy, labels_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data is prepared for the ML model.\n",
    "First, shuffle randomly but with the same seed the two vectors prepared earlier.\n",
    "From the \"features_noisy\" numpy array, both the train as well as the test features are obtained via the train_test_split function and a test_size set to 0.3. The same is repeated for the train and test labels, starting from the \"labels_noisy\" array. Later, since the feature and the label train arrays slightly differ in terms of scales, a normalization process starts, with the employment of the StandardScaler() function for both the x and the y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 99\n",
    "\n",
    "random.Random(k).shuffle(features_noisy)\n",
    "random.Random(k).shuffle(labels_noisy)\n",
    "\n",
    "\n",
    "train_features, test_features = train_test_split(features_noisy, test_size = 0.3, random_state = 0)\n",
    "train_labels, test_labels = train_test_split(labels_noisy, test_size = 0.3, random_state = 0)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "x_train = scaler_X.fit_transform(train_features.reshape(-1, 1)).flatten()\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "y_train = scaler_Y.fit_transform(train_labels.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model, here called \"model\". This consists in a very simple model containing only 1 Dense node and 1 Dropout node, which goes to eliminate 40% of the data fed to the model each time. I included this since it let the model avoid overfitting and actually learn something. As it can be seen by the model summary, the total number of parameters equals 2, which is necessary for a linear regression to a straight line. The optimizer chosen is Adam, while the quantity to be monitored for the loss is the mean squared error.\n",
    "A brief prediction on how the model handles the first ten values of the \"train_features\" array is also shown, in order to be sure that the shape of the output is the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.3276211e+09],\n",
       "       [4.8843505e+09],\n",
       "       [4.5204490e+08],\n",
       "       [4.8251725e+09],\n",
       "       [4.0318523e+09],\n",
       "       [1.2189226e+10],\n",
       "       [1.2210601e+09],\n",
       "       [2.9127124e+09],\n",
       "       [7.7075743e+09],\n",
       "       [1.3673005e+09]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(units = 1, input_shape = (1,)),\n",
    "    Dropout(0.4)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer = 'Adam', loss = 'mse')\n",
    "keras.utils.plot_model(model)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 3.1375 - val_loss: 1.8871\n",
      "Epoch 2/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.6416 - val_loss: 1.7879\n",
      "Epoch 3/15\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 2.0966 - val_loss: 1.6754\n",
      "Epoch 4/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.4235 - val_loss: 1.6018\n",
      "Epoch 5/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 2.3770 - val_loss: 1.5002\n",
      "Epoch 6/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 2.1968 - val_loss: 1.3929\n",
      "Epoch 7/15\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 1.6285 - val_loss: 1.3457\n",
      "Epoch 8/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 3.5284 - val_loss: 1.2919\n",
      "Epoch 9/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.5648 - val_loss: 1.2315\n",
      "Epoch 10/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.7225 - val_loss: 1.1877\n",
      "Epoch 11/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 0.8746 - val_loss: 1.1675\n",
      "Epoch 12/15\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 1.3819 - val_loss: 1.1333\n",
      "Epoch 13/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.5936 - val_loss: 1.0928\n",
      "Epoch 14/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.3587 - val_loss: 1.0613\n",
      "Epoch 15/15\n",
      "383/383 [==============================] - 1s 2ms/step - loss: 1.0861 - val_loss: 1.0268\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "history = model.fit(x_train, y_train, epochs = epochs, verbose = 1, batch_size = 3, validation_split = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_fn = history.history[\"loss\"]\n",
    "eval_loss_fn = history.history[\"val_loss\"]\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(epochs_range, train_loss_fn, label = \"Train Loss function\")\n",
    "plt.plot(epochs_range, eval_loss_fn, label = \"Eval Loss function\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.title(\"Loss function\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid()\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = scaler_Y.inverse_transform((model.predict(scaler_X.transform(test_features.reshape(-1, 1)).flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18e72c8a7f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(np.min(dataset_fundamentals['Net Cash Flow-Operating']), np.max(dataset_fundamentals['Net Cash Flow-Operating']), len(test_labels))\n",
    "y = scaler_Y.inverse_transform(model.predict(scaler_X.transform(x.reshape(-1, 1)).flatten()))\n",
    "\n",
    "plt.scatter(dataset_fundamentals['Net Cash Flow-Operating'], dataset_fundamentals['Earnings Before Interest and Tax'],\n",
    "           label = 'Data')\n",
    "plt.plot(x, y, color = 'k', label = 'Predictions')\n",
    "plt.xlabel('Net Cash Flow-Operating')\n",
    "plt.ylabel('Earnings Before Interest and Tax')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2855159048107925"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
